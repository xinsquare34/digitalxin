<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta charset="utf-8" />
    <title>星星 - AI餐伴</title>
    <link rel="icon" href="img/favicon.png" type="image/png" />
    <link rel="stylesheet" href="globals.css" />
    <link rel="stylesheet" href="style.css" />
    <style>
      .speak-logo {
        -webkit-user-drag: none;
        user-select: none;
        cursor: pointer;
      }

      .chat-log {
        position: absolute;
        top: 240px;
        left: 1122px;
        width: 270px;
        height: 560px;
        overflow-y: auto;
        display: flex;
        flex-direction: column;
        gap: 8px;
        padding-right: 6px;
      }

      .chat-bubble {
        background-color: #f6e7e1;
        border-radius: 8px;
        padding: 8px 12px;
        color: #da9c92;
        font-family: "Poppins-SemiBold", Helvetica;
        font-weight: 600;
        font-size: 17px;
        letter-spacing: -0.36px;
        word-break: break-word;
      }

      .chat-bubble.user {
        align-self: flex-end;
        background-color: #fbdad2;
      }

      .chat-bubble.bot {
        align-self: flex-start;
      }

      .for-videos {
        width: 100%;
        height: auto;
        position: absolute;
        top: 0;
        left: 0;
      }
    </style>
  </head>
  <body>
    <div class="digital-human">
      <div class="overlap-wrapper">
        <div class="overlap">
          <video id="avatar" class="for-videos" autoplay muted playsinline preload="auto" loop style="opacity: 1;">
            <source src="img/relaxed.mp4" type="video/mp4" />
          </video>
          <video id="avatar2" class="for-videos" autoplay muted playsinline preload="auto" loop style="opacity: 0;">
            <source src="img/relaxed.mp4" type="video/mp4" />
          </video>

          <div class="text-background"></div>
          <div class="text-box-group">
            <div class="overlap-group">
              <div class="text-box"></div>
              <img class="text-box-outline" src="img/text-box-outline.svg" />
            </div>
          </div>

          <img class="speak-logo" src="img/speak-logo.png" id="speakBtn" draggable="false" />
          <div class="main-heading">星星 - 你的AI餐伴</div>
          <div class="chat-log" id="chatLog">
            <div class="chat-bubble bot">你好，我是你的餐伴星星。<br />你可以随时和我聊天哦～</div>
          </div>

          <img class="go-to-eating" src="img/go-to-eating.png" />
          <div class="eating-text">用餐陪伴点这里</div>
          <div class="by-me">By: LIU XINXIN</div>
        </div>
      </div>
    </div>

    <script>
      const avatar1 = document.getElementById("avatar");
      const avatar2 = document.getElementById("avatar2");
      const speakBtn = document.getElementById("speakBtn");
      const chatLog = document.getElementById("chatLog");

      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = "zh-CN";

      let isCalling = false;
      let currentUtterance = null;

      const messages = [
        {
          role: "system",
          content: "你是“星星”，2001年出生的女生...
        }
      ];

      speakBtn.addEventListener("mousedown", () => {
        speakBtn.src = "img/recording-text.png";
        recognition.start();
      });

      speakBtn.addEventListener("mouseup", () => {
        speakBtn.src = "img/speak-logo.png";
        recognition.stop();
      });

      recognition.onresult = async (event) => {
        const userText = event.results[0][0].transcript;
        addChatBubble("user", userText);

        const botReply = await getXingxingReply(userText);
        addChatBubble("bot", botReply);
        speakText(botReply);
      };

      function addChatBubble(sender, text) {
        const bubble = document.createElement("div");
        bubble.className = `chat-bubble ${sender}`;
        bubble.textContent = text;
        chatLog.appendChild(bubble);
        chatLog.scrollTop = chatLog.scrollHeight;
      }

      async function getXingxingReply(userInput) {
        if (isCalling) return "（星星正在思考中…）";
        isCalling = true;

        messages.push({ role: "user", content: userInput });
        if (messages.length > 21) messages.splice(1, messages.length - 21);

        const response = await fetch("https://api.deepseek.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer sk-xxxxx`,
          },
          body: JSON.stringify({ model: "deepseek-chat", messages, temperature: 0.8 })
        });

        isCalling = false;
        const data = await response.json();
        const reply = data.choices[0]?.message?.content?.trim() || "（星星有点走神了呢）";
        messages.push({ role: "assistant", content: reply });
        return reply;
      }

      function handleAvatarAction(text) {
        if (text.includes("高兴") || text.includes("太棒")) return "img/happy.mp4";
        if (text.includes("谢谢")) return "img/bow.mp4";
        if (text.includes("不知")) return "img/shrug.mp4";
        if (text.includes("推荐")) return "img/teaching.mp4";
        return Math.random() > 0.5 ? "img/talking.mp4" : "img/talking-2.mp4";
      }

      function speakText(text) {
        const videoSrc = handleAvatarAction(text);
        const current = avatar1.style.opacity === "1" ? avatar1 : avatar2;
        const next = current === avatar1 ? avatar2 : avatar1;

        const currentSource = current.querySelector("source");
        const nextSource = next.querySelector("source");

        // Cancel any previous utterance
        if (currentUtterance) {
          currentUtterance.onend = null;
          speechSynthesis.cancel();
        }

        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "zh-CN";
        utterance.pitch = 1.1;
        utterance.rate = 1.1;
        currentUtterance = utterance;

        next.pause();
        nextSource.src = videoSrc;
        next.load();

        next.oncanplay = () => {
          next.loop = true;
          next.style.opacity = "1";
          current.style.opacity = "0";
          next.play();
          speechSynthesis.speak(utterance);
        };

        utterance.onend = () => {
          next.pause();
          next.loop = false;
          currentSource.src = "img/relaxed.mp4";
          current.load();
          current.oncanplay = () => {
            current.loop = true;
            current.play();
            current.style.opacity = "1";
            next.style.opacity = "0";
          };
        };
      }
    </script>
  </body>
</html>
