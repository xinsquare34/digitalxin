
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <title>æ•°å­—äººè¯­éŸ³äº’åŠ¨ Demo - ç¨³å®šç‰ˆ</title>
  <style>
    body { margin: 0; font-family: sans-serif; background: #fbeff3; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; }
    #avatar { height: 400px; margin-bottom: 20px; transition: all 0.3s ease; }
    #reply { font-size: 1.2rem; padding: 10px 20px; background: white; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
    #speakBtn { margin-top: 20px; padding: 10px 20px; font-size: 1rem; border-radius: 8px; border: none; background: #ff7da9; color: white; cursor: pointer; }
  </style>
</head>
<body>

  <img id="avatar" src="idle.png" alt="æ•°å­—äºº">
  <div id="reply">è¯·å¯¹æˆ‘è¯´è¯å§ï½</div>
  <button id="speakBtn">ğŸ¤ æŒ‰ä½å¼€å§‹è¯´è¯</button>

<script>
const avatar = document.getElementById('avatar');
const replyBox = document.getElementById('reply');
const speakBtn = document.getElementById('speakBtn');

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();
recognition.lang = 'zh-CN';

let isCalling = false;
let useMock = false;  // ğŸ”¥ true=æœ¬åœ°æ¨¡æ‹Ÿï¼Œfalse=è°ƒç”¨OpenAI API

speakBtn.addEventListener('mousedown', () => {
  replyBox.textContent = 'ğŸ¤ å½•éŸ³ä¸­...';
  recognition.start();
});

speakBtn.addEventListener('mouseup', () => {
  recognition.stop();
});

recognition.onresult = async (event) => {
  const userText = event.results[0][0].transcript;
  replyBox.textContent = `ä½ è¯´ï¼š${userText}`;

  const botReply = await getReply(userText);
  replyBox.textContent = `æ•°å­—äººï¼š${botReply}`;

  handleAvatarAction(botReply);
};

async function getReply(userInput) {
  if (useMock) {
    return new Promise(resolve => {
      setTimeout(() => {
        if (userInput.includes("è°¢è°¢")) resolve("ä¸ç”¨å®¢æ°”ï¼Œé èº¬ï½");
        else if (userInput.includes("é«˜å…´") || userInput.includes("å¼€å¿ƒ")) resolve("æˆ‘ä¹Ÿå¾ˆé«˜å…´è§åˆ°ä½ ï¼");
        else if (userInput.includes("ä¸çŸ¥é“")) resolve("æˆ‘ä¹Ÿä¸æ¸…æ¥šå‘¢");
        else resolve("æ”¶åˆ°ï¼");
      }, 500);
    });
  } else {
    if (isCalling) {
      console.warn("è¯·ç¨åå†è¯•ï¼Œé™æµä¸­...");
      return "ï¼ˆè¯´å¾—å¤ªå¿«äº†ï¼Œè¯·ç¨åå†è¯´ï¼‰";
    }
    isCalling = true;

    const apiKey = "YOUR_OPENAI_API_KEY";  // ğŸ”¥ æ›¿æ¢æˆä½ è‡ªå·±çš„
    const endpoint = "https://api.openai.com/v1/chat/completions";

    const response = await fetch(endpoint, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: "gpt-4o",
        messages: [{ role: "user", content: userInput }],
        temperature: 0.7
      })
    });

    isCalling = false;

    if (response.status === 429) {
      console.error("429 Too Many Requests");
      return "ï¼ˆè¯´å¾—å¤ªå¿«äº†ï¼Œè¯·ç¨åé‡è¯•ï¼‰";
    }

    const data = await response.json();
    return data.choices[0]?.message?.content?.trim() || "ï¼ˆæ— å›å¤ï¼‰";
  }
}

function handleAvatarAction(replyText) {
  if (replyText.includes("é«˜å…´") || replyText.includes("å¼€å¿ƒ")) {
    avatar.src = "smile.png";
  } else if (replyText.includes("è°¢è°¢") || replyText.includes("é èº¬")) {
    avatar.src = "bow.png";
  } else if (replyText.includes("ä¸çŸ¥é“") || replyText.includes("ä¸æ¸…æ¥š")) {
    avatar.src = "shrug.png";
  } else {
    avatar.src = "idle.png";
  }
}
</script>

</body>
</html>
